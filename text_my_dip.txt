МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ
РОССИЙСКОЙ ФЕДЕРАЦИИ

ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ   
 УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ
«МОСКОВСКИЙ АВИАЦИОННЫЙ ИНСТИТУТ
 (национальный исследовательский университет)»


Институт (Филиал) № 8 «Компьютерные науки и прикладная математика»  Кафедра _806__
Группа М8О-407Б-22 Направление подготовки 01.03.02 Прикладная математика и информатика
Профиль 	Информатика										
Квалификация 		бакалавр								


ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА
БАКАЛАВРА
На тему: «Система верификации структурных документов»																																																			





Автор ВКРБ_____________________						(__________)
(фамилия, имя, отчество полностью)
Руководитель 									(__________)
(фамилия, имя, отчество полностью)
Консультант 										(__________)
(фамилия, имя, отчество полностью)
Консультант 										(__________)
(фамилия, имя, отчество полностью)
Рецензент 										(__________)
(фамилия, имя, отчество полностью)



К защите допустить

Заведующий кафедрой              							(__________)
                                 		(№ каф)                                                        (фамилия, имя, отчество полностью)
___ __________________ 20____г.    




Москва 2025

МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ
РОССИЙСКОЙ ФЕДЕРАЦИИ

ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ   
 УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ
«МОСКОВСКИЙ АВИАЦИОННЫЙ ИНСТИТУТ
 (национальный исследовательский университет)»


Институт (Филиал) № 8 «Компьютерные науки и прикладная математика»  Кафедра _806__
Группа М8О-407Б-22 Направление подготовки 01.03.02 Прикладная математика и информатика 
Профиль 	Информатика										
Квалификация 		бакалавр								
                                                                           
УТВЕРЖДАЮ
Заведующий кафедрой ___   ________  _____________
(№ каф.)      (подпись)        (инициалы, фамилия)
	           ____  __________ 20    г.


ЗАДАНИЕ
на выпускную квалификационную работу бакалавра
Обучающийся	Бычков Дмитрий Андреевич						
(фамилия, имя, отчество полностью)
Руководитель          Лукин Владимир Николаевич						
(фамилия, имя, отчество полностью
	кандидат физико-математических наук, доцент, доцент 806 кафедры МАИ		
                  ученая степень, ученое звание, должность и место работы)
1. Наименование темы 	«Система верификации структурных документов»		
2. Срок сдачи обучающимся законченной работы			24.05.2026		
3. Задание и исходные данные к работе 
Разработать систему автоматической проверки структуры документов на соответствие формальным требованиям и стандартам оформления. 	
Перечень иллюстративно-графических материалов*при наличии:
 
№ п/п	Наименование	Количество листов
1	Архитектура серверной компоненты приложения	1
2	Диаграмма работы API для управления миграциями	1
3	Пример логов выполнения миграций	1
4	Характеристика и демонстрация результатов разработки	1

4. Перечень подлежащих разработке разделов и этапы выполнения работы
п/п	Наименование раздела или эта-па	Трудоёмкость в % от
полной трудо-ёмкости
ВКРБ	Срок выполне-ния	Примеча-ние
1	Анализ предметной области и не-обходимого функционала	15	23.02.2026	
2	Разработка архитектуры	15	13.03.2026	
3	Разработка сервиса	45	29.04.2026	
4	Введение	15	09.05.2026	
5	Заключение (краткие выводы и перспективы дальнейшей разра-ботки темы)	10	24.05.2026	
	
5. Исходные материалы и пособия 
—	Мартин Клеппман Проектирование высоконагруженных приложений. - СПб.: 2018 
—	Clean Architecture // by Robert C. Martin URL: https://blog.cleancoder.com/uncle-bob/2011/11/22/Clean-Architecture.html
—	Митра Ронни, Надареишвили Иракли Микросервисы. От архитектуры до релиза. - СПб.: 2023													
6. Дата выдачи задания		10.02.2026							
	Руководитель						Лукин В.Н.	
	(подпись)
	Задание принял к исполнению			Чапкин В. В.	
	(подпись)

 
РЕФЕРАТ
Отчет о научно-исследовательской работе содержит ___ страниц, 1 кни-гу, ___ иллюстраций, ___ таблиц, ___ использованных источников, ___ при-ложений.
Ключевые слова: автоматизация проверки документов, ГОСТ 7.32, ана-лиз структуры документов, валидация требований, программная система, нормативные документы, python-docx, модульная архитектура, отчёт о НИР.
Объектом исследования является процесс проверки структуры тексто-вых документов научного и проектного характера на соответствие требовани-ям нормативных документов, в том числе ГОСТ 7.32.
Целью работы является разработка и обоснование программной систе-мы, предназначенной для автоматизированной проверки структуры докумен-тов на соответствие формальным требованиям стандартов и внутренних ре-гламентов.
В ходе выполнения работы использованы методы структурного анализа документов, функциональной декомпозиции, формализации нормативных требований, а также методы объектно-ориентированного и модульного про-ектирования программных систем.
В результате работы разработана концепция программной системы ав-томатической проверки структуры документов, предложена модульная архи-тектура обработки, обеспечивающая анализ структуры файлов формата .docx, выявление нарушений требований ГОСТ и формирование детализированного отчёта. Новизна работы заключается в гибкой архитектуре системы, допуска-ющей адаптацию к изменениям нормативной базы без переработки ядра про-граммного обеспечения.
Результаты работы могут быть использованы в образовательных орга-низациях, научных учреждениях и проектных подразделениях для повышения качества, и объективности проверки оформления документов.
Рекомендуется внедрение разработанного подхода в виде локального программного продукта, ориентированного на индивидуальную работу поль-зователей. Применение системы позволяет сократить трудоёмкость проверки документов и снизить вероятность ошибок, связанных с человеческим факто-ром.
Экономическая значимость работы выражается в снижении временных затрат на проверку оформления документов и повышении эффективности ра-боты специалистов. В перспективе возможно развитие системы в направлении интеллектуальной валидации требований и расширения функциональности за счёт внедрения методов машинного обучения.
СОДЕРЖАНИЕ
ВВЕДЕНИЕ	9
1	АНАЛИЗ СУЩЕСТВУЮЩИХ РЕШЕНИЙ	12
1.1	Понятие миграций в реляционных базах данных	12
1.2	Анализ популярных инструментов для управления миграциями	12
1.3	Проблемы существующих инструментов	14
1.4	Требований к разрабатываемому приложению	15
2	ВЫБОР АРХИТЕКТУРЫ И ПРОЕКТИРОВАНИЕ СИСТЕМЫ	17
2.1	Обоснование выбора архитектуры	17
2.2	Общая архитектура микросервисов	18
2.3	Проектирование архитектуры межсервисного взаимодействия	19
2.4	Проектирование структуры базы данных	21
2.4.1	База данных сервиса авторизации (Auth Service)	22
2.4.2	База данных сервиса миграций (Migration Service)	24
2.5	Проектирование интерфейса взаимодействия (API)	27
2.5.1	Интерфейс сервиса авторизации (Auth Service)	27
2.5.2	Интерфейс сервиса миграций (Migration Service)	29
2.5.3	Общие принципы проектирования API	31
2.6	Используемые инструменты и технологии	32
3	РЕАЛИЗАЦИЯ ПРИЛОЖЕНИЯ	35
3.1	Техническая реализация и структура микросервисов	35
3.1.1	Основные компоненты сервиса	36
3.1.2	Принадлежность компонентов слоям Чистой архитектуры	38
3.1.3	Связь между слоями: применение внедрения зависимостей	39
3.1.4	Структура кодовой базы	40
3.2	Ключевые технические решения	45
3.2.1	Подход API First	45
3.2.2	Передача транзакции через контекст	47
3.3	Документация и эксплуатация	52
3.3.1	Документация	52
3.3.2	Контейнеризация в микросервисной архитектуре	57
3.3.3	Развертывание и запуск системы	61
ЗАКЛЮЧЕНИЕ	65
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ	67
ПРИЛОЖЕНИЕ А	69
ПРИЛОЖЕНИЕ Б	70
ПЕРЕЧЕНЬ СОКРАЩЕНИЙ И ОБОЗНАЧЕНИЙ
БД	—	База данных
РБД	—	Реляционная база данных
СУБД	—	Система управления базами данных
API	—	Application Programming Interface (Программный интерфейс при-ложения)
CLI	—	Command Line Interface (Интерфейс командной строки)
CI/CD	—	Continuous Integration/Continuous Delivery (Непрерывная инте-грация и непрерывная доставка)
JSON	—	JavaScript Object Notation (Нотация объектов JavaScript)
JWT	—	JSON Web Token (Веб-токен JSON)
SQL	—	Structured Query Language (Структурированный язык запросов)
HTTP	—	Hypertext Transfer Protocol (Протокол передачи гипертекста)
REST	—	Representational State Transfer (Передача репрезентативного со-стояния)
gRPC	—	google Remote Procedure Calling (Удаленный вызов процедур Google)
ACID	—	Atomicity, Consistency, Isolation, Durability (Атомарность, Согла-сованность, Изоляция, Долговечность)
DDD	—	Domain-Driven Design (Предметно-ориентированное проектиро-вание)
UI	—	User Interface (Пользовательский интерфейс)
CRUD	—	Create, Read, Update, Delete (Создание, Чтение, Обновление, Уда-ление)
ВВЕДЕНИЕ
Современная научно‑техническая и образовательная деятельность ха-рактеризуется значительным ростом объемов создаваемой документации, включая отчеты о научно‑исследовательских работах, выпускные квалифика-ционные работы, технические задания и иные нормативно регламентирован-ные документы. К качеству оформления таких документов предъявляются строгие формальные требования, закрепленные в государственных стандар-тах, в частности в ГОСТ 7.32, а также во внутренних регламентах образова-тельных и научных организаций. Несоблюдение указанных требований при-водит к необходимости многократной доработки документов, увеличению временных затрат и снижению общей эффективности научной и учебной дея-тельности.
В настоящее время проверка соответствия структуры документов тре-бованиям стандартов, как правило, осуществляется вручную. Данный процесс является трудоемким, подверженным субъективным ошибкам и напрямую за-висит от квалификации проверяющего. При увеличении количества проверя-емых документов и усложнении нормативной базы возрастает вероятность пропуска ошибок, а также увеличивается нагрузка на преподавателей, науч-ных руководителей и сотрудников методических подразделений. Указанные обстоятельства свидетельствуют о наличии актуальной научно‑технической проблемы, связанной с автоматизацией проверки структуры документов на соответствие нормативным требованиям.
Основанием для разработки настоящей научно‑исследовательской ра-боты послужила необходимость создания программной системы, способной автоматизировать процесс анализа структуры документов формата .docx, вы-являть несоответствия требованиям ГОСТ и формировать объективный отчет о результатах проверки. В качестве исходных данных используются норма-тивные документы (ГОСТ 7.32 и смежные стандарты), а также типовые струк-туры научных и учебных работ, применяемые в образовательных организаци-ях.
Актуальность темы обусловлена возрастающей ролью стандартизации научной и учебной документации, а также необходимостью снижения трудо-емкости и повышения объективности процессов контроля качества оформле-ния документов. Новизна работы заключается в разработке модульной архи-тектуры программной системы, позволяющей адаптироваться к изменениям нормативной базы без переработки ядра программного обеспечения и обеспе-чивающей расширяемость за счет добавления новых правил и валидаторов.
В рамках работы предполагается достижение современного науч-но‑технического уровня разработки, соответствующего требованиям к надеж-ности, масштабируемости и удобству эксплуатации программных средств. Архитектурные и методические решения ориентированы на возможность дальнейшего развития системы, включая интеграцию интеллектуальных ме-тодов анализа структуры и содержания документов.
Патентные исследования в рамках данной научно‑исследовательской работы не проводились, поскольку разрабатываемое программное обеспече-ние ориентировано на учебно‑исследовательские цели и не предполагает со-здания технических решений, подлежащих правовой охране. Анализ суще-ствующих программных продуктов показал отсутствие универсальных средств, обеспечивающих автоматизированную проверку структуры докумен-тов в строгом соответствии с требованиями ГОСТ 7.32.
Метрологическое обеспечение научно‑исследовательской работы за-ключается в обеспечении воспроизводимости и объективности результатов проверки документов. Достоверность результатов достигается за счет форма-лизованного описания требований стандартов и их однозначной программной интерпретации, исключающей влияние субъективного фактора.
Настоящая работа тематически и методически связана с научно-исследовательскими и учебно-методическими работами, направленными на автоматизацию процессов подготовки и контроля качества научной и учебной документации, а также на формализацию и программную реализацию требо-ваний нормативных стандартов. В отличие от существующих исследований, ориентированных преимущественно на вспомогательные или частные аспекты оформления документов, в данной работе акцент сделан на разработке уни-версального подхода к автоматизированной валидации структуры докумен-тов, обеспечивающего воспроизводимость и объективность результатов. По-лученные результаты могут быть использованы как основа для дальнейших исследований и разработок в области интеллектуальных систем сопровожде-ния и контроля научной и учебной документации.
1	ТЕОРЕТИЧЕСКАЯ ЧАСТЬ
1.1	Анализ предметной области
Предметная область данной научно-исследовательской работы связана с процессом проверки структуры текстовых документов научного, учебного и проектного назначения на соответствие требованиям нормативных докумен-тов. К таким документам относятся отчёты о научно-исследовательских рабо-тах, курсовые и лабораторные работы, технические задания и иные докумен-ты, оформление которых регламентируется государственными стандартами и внутренними методическими указаниями организаций.
В качестве базового нормативного документа в работе рассматривается ГОСТ 7.32, устанавливающий требования к структуре и правилам оформле-ния отчётов о научно-исследовательских работах. Помимо указанного стан-дарта на практике применяются смежные ГОСТы, а также локальные регла-менты кафедр и образовательных организаций, что приводит к усложнению процесса контроля оформления документов.
Существенной особенностью предметной области является формализу-емый характер требований к структуре документов. Большинство правил ГОСТ 7.32 допускают однозначное описание в виде логических условий и проверок, что делает возможной их автоматизацию. Вместе с тем норматив-ная база подвержена изменениям, а требования различных организаций могут отличаться, что предъявляет повышенные требования к гибкости и расширя-емости разрабатываемой системы.
Таким образом, предметная область характеризуется высокой трудоём-костью текущих процессов, формализуемостью требований и необходимо-стью автоматизации контроля структуры документов при сохранении гибко-сти и адаптируемости программных средств.
1.2	Обзор существующих решений
В рамках анализа предметной области был выполнен обзор существу-ющих подходов и решений, направленных на автоматизацию проверки струк-туры и оформления документов в соответствии с требованиями ГОСТ 7.32.
В научных публикациях представлены исследования, посвящённые раз-работке интеллектуальных систем для проверки документов на соответствие требованиям ГОСТ 7.32. В частности, описываются программные решения, использующие методы искусственного интеллекта для анализа оформления отчётов о научно-исследовательских работах. Однако данные разработки но-сят преимущественно исследовательский характер и не представлены в виде стабильных программных продуктов, доступных для широкого практическо-го применения. Отсутствуют открытые исходные коды, подробная докумен-тация и сведения о полноте реализуемых проверок, а анализ зачастую осно-вывается на визуальных характеристиках страниц документа.
Широкое распространение получили различные шаблоны и редакторы документов, предназначенные для упрощения подготовки текстов в соответ-ствии с требованиями ГОСТ. Данные средства позволяют частично снизить количество ошибок на этапе создания документа, однако не обеспечивают ав-томатизированную валидацию уже готовых работ. Особенно это проявляется в случаях, когда оформление выполнялось вручную либо с использованием нестандартных шаблонов.
Существуют также отдельные программные проекты, заявляющие воз-можность проверки документов на соответствие требованиям ГОСТ. Вместе с тем доступность подобных решений ограничена, а их функциональные воз-можности и полнота реализуемых проверок недостаточно документированы. Это не позволяет гарантировать корректность анализа таких аспектов, как структура документа, вложенность разделов, соответствие оглавления содер-жанию, наличие обязательных структурных элементов и соблюдение фор-мальных требований стандарта.
Проведённый обзор показывает отсутствие универсальных программ-ных средств, обеспечивающих детерминированную и воспроизводимую про-верку структуры документов в строгом соответствии с требованиями ГОСТ 7.32. В связи с этим представляется целесообразным применение гибридного подхода, сочетающего алгоритмические методы проверки формализуемых требований с интеллектуальными методами анализа контекста и стиля текста. Такой подход позволяет обеспечить объективность, надёжность и расширяе-мость системы, а также минимизировать ошибки, остающиеся незамеченными при ручной проверке.
1.3	Требований к разрабатываемому приложению
На основе анализа предметной области были сформулированы требова-ния к разрабатываемой системе автоматизированной проверки структуры до-кументов.
2.3.1	Функциональные требования
Разрабатываемая система должна обеспечивать:
	загрузку и обработку текстовых документов формата .docx;
	автоматический анализ структуры документа с извлечением заго-ловков, уровней вложенности и структурных элементов;
	проверку соответствия структуры документа требованиям ГОСТ 7.32 и заданным правилам;
	выявление, классификацию и фиксацию нарушений нормативных требований;
	формирование детализированного отчёта о результатах проверки;
	возможность расширения набора проверяемых правил без моди-фикации ядра системы.
2.3.2	Нефункциональные требования
Система должна удовлетворять следующим нефункциональным требо-ваниям:
	обеспечивать приемлемое время обработки документа при ис-пользовании на персональных компьютерах;
	сохранять работоспособность при частичной недоступности от-дельных проверок или правил;
	обеспечивать воспроизводимость результатов проверки при по-вторном анализе идентичных документов;
	не вносить изменений во входной документ;
	обеспечивать локальную обработку данных без передачи доку-ментов на внешние сервисы;
	удобство использования. Интуитивно понятный интерфейс.
2.3.3	Требования к архитектуре и развитию системы
Архитектура системы должна быть модульной и обеспечивать:
	независимость компонентов анализа, валидации и формирования отчётов;
	возможность добавления новых типов документов и нормативных требований;
	масштабируемость и сопровождаемость программного обеспече-ния.
2	ПРОЕКТИРОВАНИЕ СИСТЕМЫ
2.1	Общая концепция системы
Разрабатываемая система представляет собой программное средство ав-томатизированной проверки структуры текстовых документов на соответ-ствие требованиям нормативных документов, в первую очередь ГОСТ 7.32. Система ориентирована на анализ уже подготовленных документов и функци-онирует в режиме валидации, не внося изменений в их содержимое.
В качестве входных данных система принимает текстовый документ в формате .docx. В процессе обработки документ преобразуется во внутреннее структурированное представление, описывающее иерархию его элементов (разделов, подразделов, приложений и иных обязательных компонентов), их взаимное расположение и порядок следования. Данное представление исполь-зуется в качестве основы для последующего анализа и проверки нормативных требований.
Результатом работы системы является отчёт о соответствии структуры документа нормативным требованиям, содержащий перечень выявленных нарушений, их тип, локализацию в документе и рекомендации по устранению. Отчёт формируется в структурированном виде, что обеспечивает возмож-ность его дальнейшего анализа и использования в процессе доработки доку-мента.
С точки зрения организации обработки информации система рассматри-вается как последовательность функциональных этапов, обеспечивающих преобразование исходного документа в формализованный результат провер-ки. В общем виде процесс функционирования включает:
	загрузку и первичную проверку корректности входного файла;
	извлечение и формализацию структуры документа с построением внутренней иерархической модели;
	проверку полученной структуры на соответствие нормативным требованиям с использованием набора формализованных правил;
	формирование итогового отчёта о результатах проверки.
Система проектируется как локальное программное средство, функцио-нирующее на персональном компьютере пользователя без использования внешних сервисов и передачи документов по сети. Такой подход обеспечива-ет независимость работы системы от сетевой инфраструктуры, а также повы-шает уровень конфиденциальности обрабатываемых данных.
Общая концепция системы ориентирована на использование в образова-тельной и научной среде, где требуется оперативная и объективная проверка большого количества документов с формализованной структурой. При этом система рассматривается как инструмент поддержки принятия решений, поз-воляющий выявлять ошибки оформления и несоответствия стандартам, а не как средство автоматического исправления документа.
2.2	Архитектура системы
Архитектура системы разрабатывается на основе функционального под-хода, при котором система рассматривается как совокупность взаимосвязан-ных подсистем, реализующих отдельные этапы процесса проверки структуры документа. Основное внимание уделяется декомпозиции процесса обработки на укрупнённые функции и определению связей между ними.
На верхнем уровне система рассматривается как «чёрный ящик», при-нимающий на вход текстовый документ и формирующий на выходе отчёт о результатах проверки. Управляющим воздействием в данном случае высту-пают требования нормативных документов, в первую очередь ГОСТ 7.32, а механизмом реализации – программные модули системы, обеспечивающие разбор структуры документа, проверку правил и формирование результатов.
Для формализации архитектуры была выполнена функциональная де-композиция процесса проверки структуры документа. В результате были вы-делены следующие укрупнённые функции:
	приём и загрузка документа;
	извлечение структурных элементов документа и формирование внутренней модели;
	проверка структуры на соответствие нормативным требованиям;
	формирование отчёта о результатах проверки.
Данная декомпозиция отражает логическую последовательность обра-ботки документа и служит основой для проектирования архитектуры систе-мы. Функциональная структура системы в подробном виде представлена в виде диаграммы на рисунке 2.1
 
Рисунок 2.1 – Диаграмма декомпозиции функций
На основе выполненной функциональной декомпозиции была построена функциональная модель системы в нотации IDEF0. Данная модель позволяет формально описать процесс функционирования системы, определить входные и выходные данные, управляющие воздействия и используемые механизмы.
В качестве входа функциональной модели выступает текстовый доку-мент в формате .docx. Выходом модели является отчёт о соответствии струк-туры документа нормативным требованиям. Управляющим воздействием яв-ляются требования ГОСТ 7.32 и связанных нормативных документов. Меха-низмами реализации являются программные модули системы, обеспечиваю-щие разбор структуры документа, применение валидаторов и формирование итоговых результатов.
Контекстная диаграмма IDEF0, отражающая архитектуру системы на верхнем уровне абстракции, представлена на рисунке 2.2.
 
Рисунок 2.2 – Контекстная диаграмма функциональной модели системы (IDEF0)
Архитектура системы предполагает использование единого внутреннего представления структуры документа, передаваемого между функциональны-ми подсистемами. Это позволяет обеспечить согласованность обработки дан-ных, избежать дублирования логики анализа и упростить расширение системы за счёт добавления новых правил и методов проверки.
Проверка нормативных требований в рамках архитектуры реализуется в виде набора независимых валидаторов, каждый из которых отвечает за от-дельное правило или группу правил. Такой подход обеспечивает модульность системы и позволяет адаптировать её к изменениям нормативной базы без из-менения базовой структуры архитектуры.
Использование нотации IDEF0 позволяет представить архитектуру си-стемы в формализованном виде, удобном для анализа, проектирования и дальнейшей детализации. Полученная модель служит основой для последу-ющего описания потоков данных и модульной структуры системы.
2.3	Модульная структура системы
Разрабатываемая система реализована в виде набора взаимосвязанных сервисных модулей, каждый из которых отвечает за строго определённый этап обработки документа. Архитектура системы построена по принципу кон-вейерной обработки данных, где результат работы одного модуля является входными данными для следующего.
В состав системы входят следующие основные модули:
2.3.1	Модуль загрузки документа (Document Loader Service)
Отвечает за приём входного файла и его первичную валидацию.
Функции модуля:
	проверка формата файла (.docx);
	проверка доступности файла для чтения;
	извлечение базовых метаданных документа;
	формирование объекта запроса на проверку;
	регистрация события загрузки в системе логирования.
На выходе модуль формирует структуру:
	идентификатор проверки;
	путь к файлу;
	метаданные документа.
Этот объект передаётся в модуль анализа структуры.
2.3.2	Модуль анализа структуры документа (Structure Parser Service)
Отвечает за разбор содержимого DOCX-файла и построение внутренней структурной модели документа.
Модуль реализует:
	чтение XML-структуры DOCX;
	извлечение заголовков и их уровней;
	определение иерархии разделов;
	формирование дерева структуры документа.
Результатом работы модуля является структурная модель документа в виде иерархического объекта:
DocumentStructure {
  sections: [
    {
      title,
      level,
      position,
      children[]
    }
  ]
}
Данная модель полностью абстрагирована от формата DOCX и исполь-зуется всеми последующими компонентами системы.
2.3.3	Модуль управления нормативными требованиями (Rules Service)
Отвечает за хранение и предоставление правил проверки, соответству-ющих ГОСТ 7.32 и локальным требованиям.
Модуль реализует:
	загрузку правил из конфигурационных файлов или базы данных;
	версионирование нормативных требований;
	группировку правил по типам проверок;
Каждое правило описывается структурой:
Rule {
  id,
  name,
  description,
  reference_to_GOST,
  severity,
  validation_type
}
2.3.4	Модуль валидации структуры (Validation Service)
Является центральным вычислительным компонентом системы.
Получает:
	структурную модель документа;
	набор нормативных правил.
Модуль реализует механизм плагин-валидаторов, где:
	каждый валидатор проверяет одно конкретное правило;
	валидаторы независимы друг от друга;
	результатом является список найденных нарушений.
Каждое нарушение содержит:
Violation {
  rule_id,
  description,
  section_reference,
  position,
  recommendation
}
2.3.5	Модуль формирования отчёта (Report Service)
Отвечает за генерацию итогового отчёта проверки.
Функции модуля:
	агрегация списка нарушений;
	сортировка по типу и критичности;
	генерация отчёта в формате PDF / HTML / TXT;
	сохранение отчёта в файловой системе.
2.3.6	Модуль логирования и мониторинга (Logging Service)
Отвечает за:
	запись всех этапов работы системы;
	хранение информации об ошибках;
	фиксацию времени выполнения операций;
	ведение истории проверок.
2.4	Потоки данных и сценарии функционирования
Общая схема потоков данных представлена на рисунке 2.3. Диаграмма отражает функциональную модель системы в нотации IDEF0 и показывает основные этапы обработки информации, а также взаимодействие между поль-зователем, хранилищами данных и функциональными блоками системы.
На вход системы поступают два основных вида данных:
	текстовый документ в формате .docx, предоставляемый пользователем;
	нормативные требования, представленные в виде формали-зованных правил на основе ГОСТ 7.32 и связанных стандар-тов.
Дополнительно используются служебные данные, такие как версии пра-вил, журналы событий и история выполненных проверок.
Сценарий функционирования системы включает следующие этапы.
2.6.1	Загрузка документа (A1).
Пользователь загружает файл формата .docx через пользовательский интерфейс. Документ сохраняется во временном хранилище (D1) и проходит первичную проверку на корректность формата и доступность для обработки. На данном этапе осуществляется базовая валидация входных данных: провер-ка расширения файла, целостности структуры документа и возможности его парсинга.
2.6.2	Извлечение структуры документа (A2).
После успешной загрузки документа выполняется его разбор и построе-ние внутреннего представления структуры. Из документа извлекаются:
	заголовки и их уровни вложенности;
	разделы и подразделы;
	элементы оглавления;
	позиции элементов в тексте;
	связи между структурными компонентами.
Результатом работы данного этапа является формализованная структу-ра документа, представленная в виде набора сущностей и связей, которая пе-редаётся на этап проверки правил.
2.6.3	Проверка соответствия нормативным требованиям (A3).
На этом этапе структура документа сопоставляется с нормативными правилами, хранящимися в базе нормативных требований (D2). Каждое пра-вило описывает:
	тип требования;
	наименование и описание;
	параметры проверки;
	степень критичности нарушения;
	ссылку на источник (пункт ГОСТ или иного стандарта).
Система последовательно применяет правила к элементам структуры документа и формирует набор результатов проверок, каждый из которых со-держит:
	идентификатор проверяемого элемента;
	идентификатор нормативного требования;
	статус проверки (выполнено / нарушено);
	описание выявленного несоответствия (при наличии).
2.6.4	Формирование отчёта (A4).
На основе результатов проверок осуществляется генерация итогового отчёта. Отчёт может формироваться в виде PDF-документа или иного форма-та, удобного для анализа пользователем. В отчёт включаются:
	общее резюме проверки;
	перечень выявленных нарушений;
	ссылки на соответствующие пункты нормативных докумен-тов;
	указание местоположения ошибок в исходном документе;
	рекомендации по устранению нарушений.
Отчёт сохраняется в хранилище истории отчётов пользователя (D4), а также информация о выполненной проверке фиксируется в журнале логиро-вания (D3).
2.6.5	Выдача результата пользователю (A5).
Сформированный отчёт передаётся пользователю через интерфейс си-стемы. Пользователь получает уведомление о завершении проверки и доступ к результатам анализа.
Таким образом, система реализует полный замкнутый цикл обработки данных: от загрузки исходного документа до формирования формализованно-го отчёта и сохранения истории проверок.
 
Рисунок 2.3 – Схема потоков данных
Для описания внутренней структуры данных и связей между сущностя-ми системы используется модель «сущность–связь», представленная на ри-сунке 2.4. Данная диаграмма отражает логическую структуру предметной об-ласти и показывает, каким образом связаны между собой документы, норма-тивные требования, элементы документа и результаты проверок.
Ключевыми сущностями являются:
	Документ – объект, представляющий загруженный пользо-вателем файл. Хранит идентификатор, версию используе-мых нормативных правил и дату выполнения проверки.
	Нормативное требование – формализованное представление отдельного правила ГОСТ или иного стандарта. Содержит тип требования, наименование, описание, параметры про-верки и ссылку на нормативный источник.
	Элемент документа – структурный компонент документа (раздел, подраздел, заголовок, текстовый элемент и т.д.), для которого выполняется проверка. Хранит информацию о названии, позиции в документе и принадлежности к кон-кретному разделу.
	Результат проверки – сущность, фиксирующая факт соот-ветствия или несоответствия элемента документа конкрет-ному нормативному требованию. Включает описание ошиб-ки, степень критичности и параметры проверки.
	История проверки – совокупность результатов, относящих-ся к одному запуску системы для конкретного документа.
	Сформированный отчёт – итоговый документ, агрегирую-щий все результаты проверки и предназначенный для поль-зователя.
 
Рисунок 2.3 – Схема сущность связь
2.5	Обоснование архитектурных решений
Система спроектирована как модульный конвейер обработки (pipeline), где каждый модуль выполняет строго определённую функцию и передаёт ре-зультат следующему модулю. Такая организация обеспечивает слабую связ-ность компонентов и их независимость:
1)	загрузка
2)	извлечение структуры
3)	проверка правил
4)	формирование отчёта
Такой подход обеспечивает ясное разделение ответственности, упроща-ет тестирование и поддержку, а также облегчает расширение (добавление но-вых валидаторов и типов документов).
2.6	Используемые инструменты и технологии
Разрабатываемая система реализована как кроссплатформенное про-граммное средство, ориентированное на локальное использование и модуль-ную архитектуру. В качестве основного языка программирования выбран Python, поскольку он обладает развитой экосистемой библиотек для обработ-ки текстовых документов, удобен для быстрого прототипирования и широко применяется при разработке аналитических и валидационных систем.
Основные используемые технологии и инструменты можно разделить на несколько групп.
2.6.1	Язык программирования и среда выполнения
В качестве основного языка реализации используется Python версии 3.10+.
Выбор Python обусловлен следующими причинами:
	наличие библиотек для работы с форматом .docx;
	удобство реализации алгоритмов разбора структуры доку-мента;
	простота создания модульных и расширяемых архитектур;
	хорошая поддержка логирования, тестирования и работы с БД.
В качестве менеджера виртуального окружения применяется:
	venv или Poetry – для изоляции зависимостей проекта.
2.6.2	Обработка документов
Для работы с документами формата .docx используются следующие библиотеки:
	python-docx – для чтения структуры документа, получения заголовков, параграфов, таблиц и их свойств;
	lxml – для низкоуровневой обработки XML-структуры до-кумента;
	zipfile – для анализа внутренней структуры docx как ZIP-архива.
Данные библиотеки позволяют:
	извлекать структуру документа;
	определять уровни заголовков;
	анализировать вложенность разделов;
	получать позиции элементов в документе.
2.6.3	Механизм проверки нормативных требований
Для реализации логики валидации применяется комбинация:
	собственных алгоритмов на Python;
	правил, описанных в виде конфигурационных файлов ( JSON или YAML).
Пример используемых форматов:
	JSON/YAML для хранения нормативных требований:
	тип требования;
	параметры проверки;
	степень критичности;
	ссылка на пункт ГОСТ;
	описание ошибки.
Это обеспечивает:
	независимость логики проверки от кода;
	возможность обновления нормативной базы без перекомпи-ляции системы;
	удобство расширения системы новыми стандартами.
2.6.4	Формирование отчётов
Для генерации отчётов используются:
	reportlab – для формирования PDF-документов;
	либо jinja2 + weasyprint – для генерации HTML и последу-ющей конвертации в PDF;
	pandas – для структурирования результатов проверок перед формированием отчёта (табличные представления ошибок).
Отчёт включает:
	сводную информацию;
	таблицы нарушений;
	ссылки на нормативные пункты;
	описание ошибок и рекомендации.
2.6.5	Хранение данных
Для хранения служебных данных системы используется SQLite или PostgreSQL:
	SQLite – для локального использования и одиночных запус-ков;
	PostgreSQL – при расширении системы и многопользова-тельском режиме.
В базе данных хранятся:
	нормативные требования;
	версии правил;
	история проверок;
	логи выполнения;
	сведения о сформированных отчётах.
Для работы с БД применяются:
	SQLAlchemy – как ORM для абстрагирования от конкрет-ной СУБД;
	Alembic – для управления миграциями структуры базы дан-ных.
2.6.6	Логирование и мониторинг
Для логирования используется стандартный модуль Python:
	logging.

Реализуются следующие уровни логирования:
	INFO – основные этапы работы системы;
	WARNING – потенциальные проблемы;
	ERROR – ошибки обработки документов;
	DEBUG – детальная отладочная информация.
Логи сохраняются:
	в текстовые файлы;
	при необходимости — в базу данных.
Для ротации логов применяется:
	logging.handlers.RotatingFileHandler.
2.6.7	Контейнеризация и развертывание
Для унификации среды выполнения и упрощения развертывания систе-мы используется Docker:
	Docker – контейнеризация приложения;
	docker-compose – для запуска системы вместе с базой дан-ных и вспомогательными сервисами.
Типовая конфигурация включает:
	контейнер с Python-приложением;
	контейнер с PostgreSQL;
	тома для хранения логов и отчётов.
Это обеспечивает:
	воспроизводимость окружения;
	независимость от ОС пользователя;
	удобство переноса системы между машинами.
2.6.8	Система контроля версий
Для управления исходным кодом применяется:
	Git;
	удалённый репозиторий на GitHub или GitLab.
Используемые практики:
	раздельные ветки для разработки и стабильной версии;
	оформление коммитов с описанием изменений;
	ведение файла README с описанием сборки и запуска про-екта.
2.6.9	Тестирование
Для тестирования применяются:
pytest – модульное тестирование;
тесты для:
	парсинга документов;
	проверки отдельных нормативных правил;
	формирования отчётов.
Это обеспечивает:
	стабильность работы системы;
	возможность автоматической проверки корректности изме-нений.
2.6.10	Пользовательский интерфейс
Возможные варианты реализации:
	консольный интерфейс (CLI) на базе argparse или click;
	графический интерфейс:
	PyQt или Tkinter;
	либо web-интерфейс на FastAPI + HTML.
В черновой реализации допустимо использование CLI
3	РЕАЛИЗАЦИЯ ПРИЛОЖЕНИЯ
3.1	Техническая реализация и структура микросервисов
В данном разделе подробно описывается техническая архитектура и ре-ализация ключевых компонентов системы микросервисов. Для иллюстрации выбран сервис управления миграциями (Migration Service), как пример, де-монстрирующий основные принципы организации кода, взаимодействия слоев и применения архитектурных паттернов. На рисунке 3.1 показаны архитектур-ные компоненты и их взаимодействие с другими компонентами.
 
Рисунок 3.1 – Диаграмма архитектурных компонентов и их взаимодействия
Архитектура сервиса основывается на принципах Чистой архитектуры (Clean Architecture), адаптированных под специфику разработки на языке Go, с акцентом на разделение ответственности и инверсию зависимостей [17]. Цель раздела — показать, как применяются выбранные подходы, и как ком-поненты взаимодействуют между собой.
3.1.1	Основные компоненты сервиса
1)	Config (internal/config) Централизованный модуль, ответственный за за-грузку и хранение всех конфигурационных параметров приложения. Включает:
°	AppConfig: общие настройки приложения (название, версия).
°	LogConfig: конфигурация подсистемы логирования (уровень детализа-ции).
°	PostgresConfig: параметры подключения к базе данных PostgreSQL.
°	GRPCConfig, HTTPConfig: адреса и порты для сетевых служб.
2)	GrpcService (internal/adapters/grpc) Адаптер внешнего уровня, реализу-ющий публичный gRPC API сервиса. Он преобразует входящие gRPC-запросы, вызывает соответствующие методы бизнес-логики (интерфейса Migrator) и формирует ответы. Предоставляет следующие методы:
°	ApplyMigration: применение миграции.
°	CreateMigration: создание нового файла миграции.
°	GetMigration: получение информации о конкретной миграции.
°	ListMigrations: получение списка всех миграций.
°	RollbackMigration: откат примененной миграции.
3)	Migrator (internal/services/migrator) Слой бизнес-логики – ядро сервиса. Содержит основные сценарии использования (Use Cases) для управления миграциями. Компонент не зависит от деталей реализации внешних си-стем (БД, API), взаимодействуя с ними через абстракции (интерфейсы). Функциональность включает:
°	Управление жизненным циклом миграции (создание, применение, от-кат).
°	Взаимодействие с хранилищем миграций через интерфейс репозито-рия (MigrationRepository).
4)	MigrationRepository (internal/repository/migration) Слой доступа к дан-ным, реализующий взаимодействие с базой данных PostgreSQL для по-стоянного хранения информации о миграциях. Предоставляет методы для выполнения CRUD-операций над записями миграций. Зависит от абстрак-ции пула соединений (PGPool).
5)	MigrationInfo & MigrationStatus (internal/entity) Основные доменные сущности – структуры данных, используемые в бизнес-логике и передава-емые между слоями.
°	MigrationInfo: детальная информация о миграции (ID, имя, скрипт, статус, метаданные).
°	MigrationStatus: перечисление возможных состояний миграции (ожи-дает, применена, откатана).
6)	PGPool (pkg/postgres) Инфраструктурный компонент, управляющий пу-лом соединений с базой данных PostgreSQL. Предоставляет стандартизи-рованный интерфейс для выполнения запросов к БД, скрывая детали управления соединениями. Его конфигурация загружается из Config.
7)	Logger (pkg/logger) Компонент инфраструктуры, ответственный за струк-турированное логирование событий приложения в формате JSON. Уро-вень логирования определяется параметрами из LogConfig.
8)	DbInitializerService (internal/services/initializer) Сервис, отвечающий за координацию первоначальной инициализации структуры базы данных при первом запуске приложения. Взаимодействует с репозиторием инициали-зации.
9)	InitRepository (internal/repository/initier) Репозиторий инфраструктур-ного уровня, выполняющий низкоуровневые операции с базой данных, необходимые для инициализации, например, создание системных таблиц (таблицы истории миграций), если они еще не существуют.
3.1.2	Принадлежность компонентов слоям Чистой архитектуры
Структура сервиса организована в соответствии с принципами Чистой архитектуры, где зависимость направлена внутрь, к ядру системы (бизнес-логике). Соответствие компонент со слоями чистой архитектуры представле-но в таблице 3.1.
Таблица 3.1 – Соответствие компонент со слоями чистой архитектуры
Компонент	Слой в Чистой архитектуре	Описание слоя в контексте проекта
GrpcService	Адаптеры (Interface)	Преобразует данные из внешнего формата (gRPC-запросы/ответы) в формат, понятный ядру, и наоборот.
MigrationRepository	Адаптеры (Data)	Реализует интерфейс, опре-деленный на уровне бизнес-логики, для взаимодействия с внешним хранилищем дан-ных.
InitRepository	Адаптеры (Data)	Репозиторий, выполняющий инфраструктурные операции инициализации БД.
PGPool	Адаптеры (Data)	Предоставляет интерфейс для доступа к базе данных, скрывая детали реализации конкретной СУБД.
Migrator	Сценарии использования (Use Cases)	Содержит специфичную для приложения бизнес-логику. Определяет, как сущности используются для достиже-ния целей приложения.
DbInitializerService	Сценарии использования (Use Cases)	Сервис, координирующий взаимодействие с инфра-структурным репозиторием для начальной настройки.
MigrationInfo, Migra-tionStatus	Сущности (Entities)	Основные бизнес-объекты приложения. Находятся в самом внутреннем слое.
Config	Инфраструктура / Утилиты (Utilities)	Предоставляет конфигураци-онные данные для инициали-зации компонентов внешних слоев.
Logger	Инфраструктура / Утилиты (Utilities)	Предоставляет функцио-нальность логирования, ис-пользуемую различными слоями.
В данной структуре ядро системы — Migrator — не имеет прямых зави-симостей от конкретных реализаций адаптеров (базы данных, сетевого прото-кола). Взаимодействие происходит через интерфейсы, что обеспечивает сла-бую связанность и облегчает замену реализаций (например, использование другой СУБД или протокола API) и модульное тестирование.
3.1.3	Связь между слоями: применение внедрения зависимостей
Взаимосвязь между компонентами строится на принципе инверсии зави-симостей, реализуемом через внедрение зависимостей (Dependency Injection). Вместо того чтобы компоненты сами создавали или напрямую ссылались на конкретные реализации своих зависимостей, эти зависимости предоставляют-ся им извне, обычно через конструктор. Зависимости всегда направлены внутрь, к более высоким уровням абстракции (интерфейсам) [18].
Например, Migrator (бизнес-логика) зависит от абстракции MigrationRepository (интерфейса), а не от его конкретной реализации (PostgresMigrationRepository). Конкретная реализация PostgresMigrationRepository внедряется в Migrator при его создании.
Пример внедрения зависимости через конструктор:
// src/internal/services/migrator/migrator.go

type migrationRepository interface {
    Get(ctx context.Context, migrationID int64) (entity.MigrationInfo, error)
}

type Migrator struct {
    repo migrationRepository
}

func NewMigrator(repo migrationRepository) *Migrator {
    return &Migrator{repo: repo}
}
3.1.4	Структура кодовой базы
Для обеспечения логической организации, упрощения процессов разра-ботки, тестирования и сопровождения микросервиса управления миграциями (Migration Service) была реализована следующая структура кодовой базы, со-ответствующая принципам чистой архитектуры и стандартным практикам ор-ганизации Go-проектов:
migrator
├── api
│   ├── google
│   │   └── api
│   │       ├── annotations.proto
│   │       ├── http.proto
│   │       └── httpbody.proto
│   ├── migrator
│   │   ├── migrator.proto
│   │   └── migrator.swagger.json
│   └── protoc-gen-openapiv2
│       └── options
│           ├── annotations.proto
│           └── openapiv2.proto
├── bin
│   ├── migrator
│   ├── protoc-gen-go
│   ├── protoc-gen-go-grpc
│   ├── protoc-gen-grpc-gateway
│   ├── protoc-gen-openapiv2
│   └── swagger
├── cmd
│   └── migrator
│       └── main.go
├── config
│   ├── config.go
│   └── config.yaml
├── internal
│   ├── adapters
│   │   ├── grpc
│   │   │   └── server.go
│   │   └── repository
│   │       ├── intiter
│   │       │   └── initer.go
│   │       └── migration
│   │           └── migration.go
│   ├── entity
│   │   └── migration.go
│   └── services
│       ├── initializer
│       │   └── initializer.go
│       └── migrator
│           └── migrator.go
├── pkg
│   ├── api
│   │   └── migrator
│   │       ├── migrator.pb.go
│   │       ├── migrator.pb.gw.go
│   │       └── migrator_grpc.pb.go
│   ├── logger
│   │   ├── global.go
│   │   └── logger.go
│   └── postgres
│       ├── options.go
│       └── postgres.go
├── Dockerfile
├── go.mod
├── go.sum
└── makefile
—	cmd/migrator/: каталог содержит точку входа в приложение (main.go). Здесь происходит инициализация всех ключевых компонентов сервиса: загрузка конфигурации, настройка системы логирования, установка со-единения с базой данных, регистрация и запуск gRPC и HTTP серверов.
—	config/: содержит структуры данных и логику для загрузки параметров приложения из конфигурационного файла config.yaml.
°	config.go: определяет структуры конфигурации (например, AppConfig, PostgresConfig) и функцию для их парсинга и загрузки.
°	config.yaml: пример конфигурационного файла, содержащего все не-обходимые для работы сервиса параметры (сетевые порты, учетные данные для подключения к БД и т.д.).
—	api/: включает спецификации API сервиса и сопутствующие файлы.
°	google/api/: содержит стандартные ProtoBuf-файлы от Google (annotations.proto, http.proto, httpbody.proto), используемые для расширенного аннотирования gRPC-сервисов, определения HTTP-маршрутов и описания тел HTTP-запросов/ответов.
°	migrator/: содержит специфичные для сервиса файлы.
—	migrator.proto: основной ProtoBuf-файл, описывающий интер-фейс gRPC API сервиса миграций, включая определения серви-сов, сообщений и RPC-методов.
—	migrator.swagger.json: автоматически сгенерированный файл спецификации OpenAPI (Swagger) на основе migrator.proto, предназначенный для документирования и тестирования REST API, предоставляемого через gRPC-gateway.
—	pkg/: содержит общеиспользуемые библиотеки и утилиты, предназначен-ные для повторного использования в различных частях проекта или даже в других сервисах.
°	api/migrator/: каталог для сгенерированного Go-кода из ProtoBuf-спецификации migrator.proto.
—	migrator.pb.go: сгенерированный код из ProtoBuf-сообщения.
—	migrator.pb.gw.go: сгенерированный код для gRPC-gateway, обеспечивающий трансляцию HTTP/JSON в gRPC.
—	migrator_grpc.pb.go: сгенерированный код, содержащий интер-фейсы и реализации gRPC клиента и сервера.
°	logger/: модуль, предоставляющий функциональность логирования.
—	global.go: инициализация и управление глобальным экземпля-ром логгера.
—	logger.go: реализация структурированного логгера, использую-щего, например, библиотеку Zerolog.
°	postgres/: утилиты для работы с базой данных PostgreSQL.
—	options.go: структуры и функции для определения параметров подключения к БД.
—	postgres.go: реализация пула соединений и базовых методов взаимодействия с PostgreSQL.
—	bin/: каталог для хранения исполняемых файлов, генерируемых в процес-се сборки или необходимых для выполнения различных задач проекта (например, генерация кода).
°	Включает сгенерированные утилиты protoc-gen-go, protoc-gen-go-grpc, protoc-gen-grpc-gateway, protoc-gen-openapiv2, инструмент swagger для работы со спецификациями.
—	internal/: содержит основную часть бизнес-логики приложения, адаптеры и доменные сущности. Согласно соглашениям Go, код в каталоге не пред-назначен для импорта извне проекта.
°	adapters/: реализации внешних зависимостей, выступающие в роли адаптеров, взаимодействующих с инфраструктурным слоем (база данных, сетевые протоколы).
—	grpc/: содержит реализацию gRPC-сервера, обрабатывающего входящие запросы.
°	server.go: имплементация интерфейсов gRPC-сервиса, вызы-вающая соответствующую бизнес-логику из слоя services.
—	repository/: реализации интерфейсов репозиториев для доступа к данным.
°	intiter/: реализация репозитория для инфраструктурных операций инициализации схемы базы данных (initer.go).
°	migration/: реализация репозитория для выполнения CRUD-операций над сущностью “миграция” (migration.go), взаимо-действующая непосредственно с базой данных.
°	entity/: содержит определения доменных сущностей — основных бизнес-объектов приложения. Самый внутренний слой чистой архи-тектуры.
—	migration.go: определения структур данных MigrationInfo и MigrationStatus, используемых на всех уровнях приложения.
°	services/: содержит слой сценариев использования (Use Cases) и биз-нес-логики, которая координирует работу с сущностями и адаптера-ми.
—	initializer/: сервис, ответственный за координацию процесса начальной инициализации базы данных (initializer.go), ис-пользуя соответствующий репозиторий.
—	migrator/: основной сервис, реализующий главные сценарии ис-пользования приложения, такие как применение, откат и полу-чение статуса миграций (migrator.go). Он зависит от интерфей-сов репозиториев, а не от их конкретных реализаций.
—	Dockerfile: определяет шаги для сборки контейнерного образа сервиса, включая установку зависимостей, генерацию кода, компиляцию приложе-ния и определение точки входа для запуска.
—	go.mod, go.sum: файлы, используемые системой Go Modules для управления зависимостями проекта.
—	makefile: файл автоматизации с набором типовых команд (целей) для сборки приложения (make build), запуска (make run), генерации кода (make generate), сборки Docker-образа (make docker-build), запуска тестов (make test) и других рутинных операций.
Такая структура кодовой базы обеспечивает четкое разделение ответ-ственности между модулями и слоями, соответствует принципам чистой ар-хитектуры, способствует слабой связанности компонентов и значительно упрощает процессы тестирования, сопровождения и дальнейшего развития проекта, повышая его масштабируемость.
3.2	Ключевые технические решения
3.2.1	Подход API First
В процессе создания сервисов был применён подход API First, при ко-тором проектирование и спецификация API предшествуют непосредственной разработке системы. Метод обеспечивает структурированное и предсказуемое взаимодействие между компонентами – важное условие для построения надёжной и масштабируемой архитектуры.
3.2.1.1	Преимущества применения подхода API First
Использование подхода API First обеспечило ряд значимых преиму-ществ, способствующих эффективности и качеству разработки:
1)	Чёткая спецификация и документация
°	Файлы .proto предоставляют однозначное описание API, что устра-няет неопределённости и упрощает понимание системы.
°	Автоматически генерируемая документация в формате OpenAPI (Swagger) на основе .proto файлов обеспечивает актуальное и детали-зированное представление всех конечных точек. В проекте файл migrator.swagger.json используется для визуализации API в Swagger UI, что повышает прозрачность и облегчает освоение сервиса новыми членами команды и сторонними интеграторами.
2)	Автоматизация процессов разработки
°	Генерация кода из .proto файлов сокращает время на создание стан-дартных элементов (например, структур данных и сериализаторов), снижая вероятность ошибок.
°	Решение позволило сосредоточить усилия на разработке бизнес-логики, повысив общую эффективность процесса.
3)	Стабильность и совместимость
°	Protocol Buffers поддерживает обратную совместимость и управление версиями, что упрощает развитие API без нарушения работы суще-ствующих клиентов.
°	Чётко определённые контракты обеспечивают устойчивость интер-фейсов, что особенно важно для систем с высокой нагрузкой и ча-стыми обновлениями.
4)	Гибкость протоколов взаимодействия
°	Использование gRPC как основного протокола гарантирует высокую производительность за счёт бинарной сериализации и поддержки по-токов.
°	HTTP-шлюз, сгенерированный из тех же .proto файлов, предоставля-ет RESTful API, делая сервис доступным для клиентов, не поддержи-вающих gRPC.
5)	Прозрачность и доступность документации
°	Автоматически генерируемая документация в формате OpenAPI (Swagger) служит актуальным источником информации для даль-нейшей интеграции в сложные инфраструктуры. В проекте файл migrator.swagger.json используется для визуализации API в Swagger UI, что упрощает его тестирование и использование сторонними пользователями.
6)	Стандартизация и повторное использование
°	Определение структур данных и методов в .proto файлах способству-ет единообразию, что упрощает повторное использование компонен-тов в других сервисах или проектах.
3.2.1.2	Обоснование целесообразности подхода API First
Применение подхода API First было обусловлено его способностью за-ложить прочный фундамент для разработки на ранних этапах. Чёткое опреде-ление API в виде .proto файлов позволило установить строгие и прозрачные стандарты взаимодействия, исключающие неоднозначности. Решение способ-ствовало созданию устойчивого и предсказуемого API, что имеет критическое значение для микросервисных систем с регламентированным взаимодействи-ем между компонентами.
3.2.1.3	Реализация и практическое применение
На начальном этапе был разработан файл спецификации API в формате Protocol Buffers (migrator.proto). В нём были определены структуры данных (сообщения) и методы сервиса адаптера (GrpcService), включая такие опера-ции, как CreateMigration, ApplyMigration, RollbackMigration и ListMigrations. Файл стал основой для автоматической генерации кода на языке Go с исполь-зованием инструмента protoc и соответствующих плагинов (protoc-gen-go, protoc-gen-go-grpc, protoc-gen-grpc-gateway). Сгенерированный код включал структуры данных, интерфейсы gRPC и HTTP-шлюзы, что позволило сосре-доточиться на реализации бизнес-логики на основе заранее заданных контрак-тов. Кроме того, автоматически сгенерированная документация в формате Swagger (migrator.swagger.json) предоставила визуальное представление API, актуальную информацию о доступных методах и структурах данных, значи-тельно упростило тестирование и интеграцию сервиса.
Подход API First с использованием Protocol Buffers и gRPC стал ключе-вым элементом в создании надёжного и масштабируемого сервиса. Он обес-печил чёткость спецификации, автоматизацию разработки, гибкость взаимо-действия и высокую прозрачность документации, что делает систему подго-товленной для интеграции в сложные инфраструктуры и её дальнейшего раз-вития.
3.2.2	Передача транзакции через контекст
В рамках реализации сервисов в микросервисной архитектуре было уделено особое внимание обеспечению атомарности и надежности операций с базой данных. Для централизованного управления транзакциями на уровне бизнес-логики был применён подход передачи объекта транзакции через кон-текст выполнения запроса. Механизм обеспечивает гибкость, изолированность и предсказуемость операций, гарантируя согласованность данных даже при возникновении ошибок.
3.2.2.1	Реализация механизма
Основа механизма, использование объекта context.Context для передачи активной транзакции между уровнями приложения – от бизнес-логики до ре-позитория.
1)	Инициация и управление транзакцией:
 	В репозитории (Repository) был разработан метод DoInTransaction, кото-рый инкапсулирует логику начала, фиксации и отката транзакции:
 	func (r *Repository) DoInTransaction(ctx context.Context, f func(ctx context.Context) error) error {
    tx, err := r.Do(ctx).Begin(ctx)
    if err != nil {
        return err
    }
    defer func() {
        if err := tx.Rollback(ctx); err != nil {
            logger.Error(fmt.Errorf("transaction rollback error: %w", err))
        }
    }()

    ctx = context.WithValue(ctx, txKey{}, tx)

    err = f(ctx)
    if err != nil {
        return err
    }

    return tx.Commit(ctx)
}
°	Метод DoInTransaction принимает контекст ctx и функцию f, содер-жащую бизнес-логику, требующую выполнения в рамках одной тран-закции.
°	Начинается новая транзакция (r.Do(ctx).Begin(ctx)).
°	Объект транзакции pgx.Tx помещается в контекст ctx с использовани-ем приватного ключа txKey{}. Обновленный контекст передается в функцию f.
°	Используется отложенная функция (defer) для гарантированного от-ката транзакции в случае ошибки или паники до момента явной фик-сации.
°	Если выполнение функции f завершается без ошибки, транзакция фиксируется (tx.Commit).
2)	Выбор исполнителя запроса:
 	Для того чтобы методы репозитория могли использовать либо активную транзакцию из контекста, либо прямое соединение с базой данных, реали-зован метод Do:
 	func (r *Repository) Do(ctx context.Context) Executor {
    tx, ok := ctx.Value(txKey{}).(pgx.Tx)
    if ok && isValidTx(tx) { // Проверка наличия и валид-ности транзакции в контексте
        return tx
    }
    return r.conn // Возвращает прямое соединение, если транзакция отсутствует или невалидна
}
°	Метод Do(ctx) проверяет наличие объекта транзакции в контексте по ключу txKey{}.
°	Если транзакция найдена и валидна, возвращается объект pgx.Tx, реа-лизующий интерфейс Executor.
°	В противном случае возвращается основное соединение с базой дан-ных r.conn, которое аналогично реализует интерфейс Executor.
°	Таким образом, методы репозитория всегда работают с абстракцией Executor, оставаясь агностиками относительно того, выполняются ли операции в транзакции или напрямую.
3.2.2.2	Применение в бизнес-логике
Репозитории используют метод Do(ctx) для выполнения запросов к базе данных. Пример метода репозитория, получающего информацию о последней примененной миграции:
func (r *Repository) GetLatestAppliedMigration(ctx context.Context) (entity.MigrationInfo, error) {
    var migration entity.MigrationInfo
    err := r.Do(ctx).QueryRow(ctx, getLatestAppliedMigrationQuery, entity.StatusApplied).
        Scan(
            &migration.ID,
            &migration.Name,
            &migration.Description,
            &migration.Script,
            &migration.RollbackScript,
            &migration.Status,
            &migration.CreatedBy,
            &migration.StatusUpdatedAt,
        )
    if err != nil {
        if err == pgx.ErrNoRows {
            return entity.MigrationInfo{}, nil
        }
        return entity.MigrationInfo{}, fmt.Errorf("get latest applied migration: %w", err)
    }
    return migration, nil
}
Бизнес-логика, требующая выполнения нескольких операций репозито-рия в рамках одной транзакции (например, применение скрипта миграции и обновление ее статуса), вызывает DoInTransaction:
err := repo.DoInTransaction(ctx, func(ctx context.Context) error {
    // Все вызовы методов repo в функции будут ис-пользовать транзакцию из переданного ctx
    migration, err := repo.GetLatestAppliedMigration(ctx)
    if err != nil {
        return err
    }
    // ... дополнительные операции, которые должны быть частью той же транзакции ...
    // err := repo.ApplyMigrationScript(ctx, migration.Script)
    // if err != nil { return err }
    return nil // Если все успешно, транзакция будет зафиксирована методом DoInTransaction
}) 
3.2.2.3	Преимущества и обоснование подхода
Применение передачи транзакции через контекст и централизация управления ею на уровне бизнес-логики предоставляют существенные пре-имущества:
1)	Централизованное и семантически ясное управление: бизнес-логика (например, сервис Migrator) определяет, какие последовательности опера-ций с базой данных должны быть атомарными, основываясь на требова-ниях предметной области, что обеспечивает семантическую ясность и ис-ключает дублирование логики управления транзакциями на более низких уровнях (например, в каждом методе репозитория), что соответствует паттернам проектирования распределенных систем [19]. Границы транзак-ций явно определены в коде, где они логически оправданы.
2)	Изоляция и снижение связанности: репозитории становятся полностью не-зависимыми от механизма управления транзакциями. Они работают с аб-стракцией Executor и не “знают”, используется ли транзакция, что резко снижает связанность между слоями бизнес-логики и доступа к данным, делая репозитории универсальными и многократно используемыми.
3)	Гибкость и контроль: бизнес-логика получает полный контроль над жиз-ненным циклом транзакции, позволяя реализовывать сложные сценарии, где необходимо выполнить несколько разнородных операций с базой данных атомарно, гибко обрабатывать ошибки, инициируя откат только при необходимости.
4)	Упрощение тестирования: передача транзакции через контекст значитель-но облегчает написание модульных тестов для бизнес-логики. Вместо ре-альной транзакции в контекст может быть передан Mock-объект, реали-зующий интерфейс Executor, что позволяет тестировать логику без реаль-ного взаимодействия с базой данных.
5)	Соответствие архитектурным принципам: подход поддерживает принци-пы чистой архитектуры и предметно-ориентированного проектирования (DDD), позволяя доменному слою (бизнес-логике) определять транзакци-онные границы, в то время как детали реализации доступа к данным скры-ты за интерфейсами репозиториев и адаптеров.
Механизм передачи транзакции через контекст представляет собой эф-фективное архитектурное решение, обеспечивающее централизованное управление транзакциями на уровне бизнес-логики. Реализация данного под-хода в микросервисах позволяет добиться высокой гибкости, изолированно-сти и надёжности операций с базой данных. Примеры кода демонстрируют, как механизм интегрируется в репозитории и бизнес-логику, подчёркивая его практическую ценность для микросервисной архитектуры. Такой подход не только соответствует требованиям разработки, но и создаёт основу для мас-штабируемости и удобства сопровождения системы.
3.3	Документация и эксплуатация
3.3.1	Документация
Документация играет ключевую роль в процессе разработки и эксплуа-тации программного обеспечения, обеспечивая прозрачность, доступность и поддержку для всех участников проекта — разработчиков, тестировщиков и администраторов. В рамках данного проекта реализованы автоматизирован-ные подходы к созданию, поддержанию и использованию документации, что способствует повышению качества разработки и упрощению интеграции си-стемы в сложные инфраструктуры. В разделе описаны методы автоматиче-ской генерации документации, инструменты для её локального развертывания и преимущества, обеспечиваемые данным подходом.
3.3.1.1	Автоматическая генерация документации
Для поддержания актуальности и минимизации ручного труда в проекте реализованы механизмы автоматической генерации документации, синхрони-зированной с изменениями в исходном коде и спецификациях API. Они поз-воляют гарантировать соответствие документации текущему состоянию си-стемы и снизить вероятность ошибок, связанных с устаревшей информацией.
3.3.1.2	Документация API (Swagger)
Документация API генерируется автоматически на основе протоколов контрактов, определённых в файлах .proto. Использование инструмента Swagger обеспечивает следующие возможности:
—	Соответствие спецификациям: автоматическая генерация из .proto-файлов гарантирует, что документация отражает текущее состояние API, включая все доступные конечные точки и их параметры. Пример документации конечных точек сервиса миграций представлен на рисунке 3.2.
 
Рисунок 3.2 – Swagger документация сервиса миграций
—	Интерактивный интерфейс: Swagger UI предоставляет удобный визуаль-ный интерфейс для изучения API и тестирования его методов. Разработ-чики могут отправлять запросы к любым конечным точкам прямо в ин-терфейсе, передавая необходимые параметры и анализируя ответы систе-мы в реальном времени. Пример выполнения запроса к API сервиса ми-граций представлен на рисунке 3.3.
 
Рисунок 3.3 – Интерактивное тестирование API в Swagger UI
—	Локальный запуск: для удобства разработчиков предусмотрен запуск Swagger UI на локальной машине с помощью команды:
 	make swagger swagger_port=8081
 	По умолчанию Swagger UI доступен на порту 8081, однако порт насаива-ется через параметр swagger_port.
3.3.1.3	Документация кода (Godoc)
Документация кода создаётся автоматически с использованием инстру-мента Godoc, который анализирует комментарии в исходном коде и форми-рует структурированную информацию о модулях и библиотеках проекта, как описано в официальной документации [20]. Основные особенности:
—	Актуальность: Godoc обновляется при каждом изменении кода, что обес-печивает разработчиков свежей информацией о структуре и функцио-нальности системы.
—	Внешние зависимости: Godoc предоставляет документацию для пакетов, используемых в проекте как внешние зависимости, что упрощает понима-ние работы с ними и интеграцию в проект. Пример внешних зависимостей — рисуок 3.4.
 
Рисунок 3.4 – Внешние зависимости проекта в Godoc
—	Проектная структура: интерфейс Godoc отражает полную структуру про-екта, включая все пакеты, интерфейсы и бизнес-логику. Структура проек-та в интерфейсе Godoc представлена на рисунке 3.5.
 
Рисунок 3.5 – Полная структура проекта в Godoc
—	Детализация пакетов: например, в пакете migrator подробно описана реа-лизация сервиса управления миграциями, включая логику обработки за-просов и взаимодействие с базой данных. Фрагмент документации пакета migrator — на рисунке 3.6.
 
Рисунок 3.6 – Документация пакета migrator в Godoc
—	Доступность: для локального запуска Godoc есть команда:
 	make godoc godoc_port=8082
 	По умолчанию документация доступна на порту 8082, с возможностью изменения порта через параметр godoc_port.
3.3.1.4	Преимущества автоматической генерации документации
Автоматизация процесса создания документации предоставляет ряд значимых преимуществ:
—	Синхронизация с кодом: исключение расхождений между документацией и реальным состоянием системы благодаря автоматическому обновле-нию.
—	Экономия ресурсов: снижение временных затрат разработчиков на под-держание документации вручную, что позволяет сосредоточиться на ключевых задачах разработки.
—	Удобство использования: локальное развертывание Swagger UI и Godoc обеспечивает быстрый доступ к документации в процессе разработки и тестирования, повышая эффективность работы команды.
Организация документирования в проекте реализована с акцентом на автоматизацию, актуальность и доступность. Использование Swagger для до-кументирования API и Godoc для документирования кода, в сочетании с воз-можностью локального развертывания, создаёт надёжную основу для сопро-вождения и масштабирования системы. Такой подход не только повышает прозрачность проекта, но и упрощает его интеграцию в более крупные инфра-структуры, обеспечивая высокий уровень поддержки и удобства процесса разработки.
3.3.2	Контейнеризация в микросервисной архитектуре
Контейнеризация – ключевой элемент разработки программного обес-печения, особенно в контексте микросервисных архитектур. Использование контейнеров, таких как Docker, позволяет стандартизировать среду выполне-ния, упрощает развертывание и обеспечивает изоляцию компонентов системы [16]. В рамках данного проекта контейнеризация реализована для микросерви-сов управления миграциями (Migration Service) и авторизации (Auth Service), для связанных сервисов документации (Swagger и Godoc) и баз данных (PostgreSQL).
3.3.2.1	Преимущества контейнеризации
Применение контейнеризации в проекте позволило достичь следующих преимуществ:
1)	Стандартизация среды выполнения
 	Контейнеры обеспечивают единообразное окружение для всех компонен-тов системы, включая зависимости, конфигурации и версии библиотек. Они устраняют проблему несоответствия окружений между разработкой, тестированием и продуктовой средой, минимизируя ошибки, связанные с различиями в конфигурации.
2)	Изоляция компонентов
 	Каждый микросервис, база данных и вспомогательные сервисы (Swagger, Godoc) запускаются в изолированных контейнерах, тем самым снижая риск конфликтов между компонентами и повышая безопасность системы за счет ограничения доступа между сервисами.
3)	Упрощение развертывания и масштабирования
 	Контейнеризация позволила автоматизировать процесс развертывания с помощью Docker Compose, который описывает зависимости и конфигура-ции всех сервисов в едином файле docker-compose.yml, что обеспечило возможность быстрого развертывания всей системы на любой совмести-мой платформе, горизонтального масштабирования отдельных сервисов при необходимости.
4)	Воспроизводимость и переносимость
 	Использование контейнеров гарантирует, что приложение будет работать одинаково на любом сервере или локальной машине, поддерживающей Docker. Упрощается процесс передачи системы между разработчиками, тестировщиками и администраторами.
5)	Автоматизация и интеграция с CI/CD
 	Контейнеризация позволяет легко интегрировать систему с системами не-прерывной интеграции и доставки (CI/CD). Docker-образы могут быть ав-томатически собраны, протестированы и развернуты, что сокращает вре-мя на выпуск новых версий и соответствует лучшим практикам автомати-зации релизов [21].
6)	Эффективное управление зависимостями
 	Все зависимости, включая библиотеки, утилиты и конфигурации, инкап-сулированы в Docker-образах. Решeние позволило избежать проблем с установкой и настройкой зависимостей, упростило обновление версий проекта.
3.3.2.2	Реализация контейнеризации
Реализация контейнеризации в проекте была выполнена с использовани-ем Docker и Docker Compose, что обеспечило структурированное управление всеми компонентами системы. Основные аспекты реализации включают:
1)	Определение Docker-образов
 	Для каждого микросервиса (Migration Service и Auth Service) были созда-ны отдельные Docker-образы, описанные в соответствующих Dockerfile. Эти файлы содержат инструкции для установки зависимостей, компиля-ции исходного кода и настройки окружения. Например, для Migration Service Dockerfile включает шаги для установки Go, копирования исход-ного кода, генерации ProtoBuf-файлов и сборки исполняемого файла.
 	# Пример Dockerfile для Migration Service
FROM golang:1.21 AS builder
WORKDIR /app
COPY . .
RUN go mod download
RUN make generate
RUN go build -o migrator cmd/migrator/main.go
CMD ["./migrator"]
 	Аналогичный подход применен для Auth Service, Swagger и Godoc, ис-пользующих специализированные Docker-образы для запуска документа-ции.
2)	Конфигурация Docker Compose
 	Файл docker-compose.yml описывает все сервисы системы, их зависимости, сетевые настройки и параметры окружения. Единая точка входа централи-зовала управление сервисами и обеспечила их корректное взаимодей-ствие. Ключевые элементы конфигурации:
°	Сервисы микросервисов: Migration Service и Auth Service настроены для работы на портах gRPC (50051) и HTTP (8080/8081), с указанием переменных окружения для подключения к базам данных и настройки логирования.
°	Базы данных: для каждого сервиса настроена отдельная база данных PostgreSQL (postgres-database и postgres-auth) с уникальными порта-ми (5434 и 5433) и томами для хранения данных.
°	Сервисы документации: Swagger и Godoc для обоих микросервисов развертываются как отдельные контейнеры, доступные на портах 8081–8085, что обеспечивает удобный доступ к документации API и кода.
°	Сетевые настройки: все сервисы объединены в единую сеть default с драйвером bridge, что обеспечивает их взаимодействие через внут-ренние DNS-имена.
3)	Управление томами и данными
 	Для обеспечения сохранности данных баз PostgreSQL были настроены Docker-тома (postgres_data и postgres_auth). Данные сохраняются между перезапусками контейнеров при необходимости, обеспечивая надежность и целостность данных.
4)	Проверка работоспособности
 	Для баз данных PostgreSQL реализованы проверки здоровья (healthcheck) с использованием команды pg_isready, что микросервисы начнут работу только после полной готовности базы данных, минимизируя ошибки при запуске системы.
 	healthcheck:
  test: ["CMD-SHELL", "pg_isready", "--quiet", "-p", "5434"]
  interval: 10s
  timeout: 5s
  retries: 5
Контейнеризация, реализованная с использованием Docker и Docker Compose, стала фундаментальным элементом архитектуры проекта. Она обеспечила стандартизацию, изоляцию и автоматизацию процессов разверты-вания, что позволило создать надежное, масштабируемое и удобное в эксплу-атации решение. Структура, заданная в docker-compose.yml, обеспечила четкое разделение ответственности между сервисами и упростила управление зави-симостями. Контейнеризация заложила основу для дальнейшего масштабиро-вания системы и ее интеграции в более сложные инфраструктуры, такие как Kubernetes.
3.3.3	Развертывание и запуск системы
В данном разделе описываются процессы развертывания и запуска си-стемы, включая ключевые команды, определенные в файлах Makefile, после-довательность действий для инициализации микросервисов и связанных ком-понентов. Описанный подход обеспечивает простоту и воспроизводимость запуска системы в локальной среде, что соответствует требованиям удобства эксплуатации и стандартизации процессов.
Для автоматизации процессов сборки, запуска и управления системой были разработаны два файла Makefile: глобальный файл на уровне проекта и локальные файлы на уровне сервиса (на примере сервиса миграций). Эти фай-лы содержат команды, упрощающие выполнение типовых операций, таких как компиляция, тестирование, генерация кода и запуск документации.
3.3.3.1.1	Глобальный Makefile (уровень проекта)
Глобальный файл Makefile определяет команды для управления всеми сервисами проекта. Основные команды:
—	build-all Выполняет компиляцию всех микросервисов (например, Migration Service и Auth Service) для целевой архитектуры (Linux, amd64).
 	cd migrator && GOOS=linux GOARCH=amd64 make build
—	run-all Запускает все сервисы, определенные в docker-compose.yml, с пред-варительной сборкой и пересозданием контейнеров.
 	docker-compose up --force-recreate --build -d
—	stop-all Останавливает и удаляет все запущенные контейнеры, освобож-дая ресурсы.
 	docker-compose down
3.3.3.1.2	Локальный Makefile (на примере сервиса миграций)
Локальный файл Makefile в директории сервиса миграций (migrator) со-держит команды для управления конкретным сервисом. Основные команды:
—	build Компилирует исполняемый файл сервиса миграций.
 	go build -o bin/migrator cmd/migrator/main.go
—	run Запускает сервис миграций напрямую без контейнеризации.
 	go run cmd/migrator.go
—	test Выполняет модульные и интеграционные тесты с учетом покрытия кода и конкурентности.
 	go test -coverprofile=cover.out -p=3 -count=2 -cover -tags=integration -race ./...
—	swagger Запускает Swagger UI для документации API сервиса на указан-ном порту (по умолчанию 8081).
 	bin/swagger serve --no-open --port $(swagger_port) api/migrator/migrator.swagger.json
—	godoc Запускает Godoc для документации кода на указанном порту (по умолчанию 8082).
 	godoc -http=:$(godoc_port)
Использование двухуровневой структуры Makefile обеспечило четкое разделение ответственности между управлением проектом в целом и отдель-ными сервисами, упрощая процессы разработки, тестирования и документи-рования.
3.3.3.2	Процесс запуска системы
Файл docker-compose.yml определяет конфигурацию всех сервисов, их зависимости и сетевые настройки. После выполнения команды make run-all запускаются следующие компоненты с соответствующими портами: - Migration Service: - Порт 50051 (gRPC): для обработки запросов по протоколу gRPC. - Порт 8080 (HTTP): для обработки REST-запросов через gRPC-gateway.
—	Auth Service:
°	Порт 50052 (gRPC): для gRPC-запросов, связанных с аутентификаци-ей и авторизацией.
°	Порт 8081 (HTTP): для REST-запросов к сервису авторизации.
—	Swagger UI (Migration Service):
°	Порт 8082: предоставляет интерактивный интерфейс для тестирова-ния API сервиса миграций.
—	Swagger UI (Auth Service):
°	Порт 8084: предоставляет интерактивный интерфейс для тестирова-ния API сервиса авторизации.
—	Godoc (Migration Service):
°	Порт 8083: обеспечивает доступ к документации кода сервиса мигра-ций.
—	Godoc (Auth Service):
°	Порт 8085: обеспечивает доступ к документации кода сервиса авто-ризации.
—	PostgreSQL (Migration Service):
°	Порт 5434: база данных для хранения информации о миграциях.
—	PostgreSQL (Auth Service):
°	Порт 5433: база данных для хранения данных пользователей, ролей и прав доступа.
После успешного выполнения команды make run-all система становится полностью доступной в локальной среде. Пользователи могут: - Отправлять запросы к API через HTTP (порты 8080, 8081) или gRPC (порты 50051, 50052). - Просматривать документацию API через Swagger UI на портах 8082 и 8084. - Изучать документацию кода через Godoc на портах 8083 и 8085. - Подключаться к базам данных через порты 5434 (Migration Service) и 5433 (Auth Service) для выполнения административных задач или анализа данных.
Развертывание и запуск системы были реализованы с использованием автоматизированных инструментов, таких как Docker Compose и Makefile, что обеспечило стандартизацию, воспроизводимость и удобство эксплуатации. Двухуровневая структура Makefile позволила четко разделить управление на уровне проекта и отдельных сервисов, упрощая процессы сборки, тестирова-ния и документирования. Выполнение команды make run-all инициирует за-пуск всех компонентов системы: микросервисов, баз данных и документации через заранее определенные порты.
ЗАКЛЮЧЕНИЕ
В рамках выполнения выпускной квалификационной работы разработа-на серверная компонента для управления миграциями в реляционных базах данных, которая обеспечивает автоматизированное, безопасное и масштаби-руемое решение для синхронизации изменений схемы базы данных в различ-ных окружениях. Разработанная компонента ориентирована на поддержку процессов непрерывной интеграции и доставки (CI/CD), предоставляя ин-струментарий для создания, применения, отката и мониторинга миграций, что делает ее востребованной в современных условиях разработки программного обеспечения.
Приложение реализовано на основе микросервисной архитектуры с применением принципов чистой архитектуры, что обеспечило модульность, слабую связанность компонентов и высокую степень масштабируемости. Ис-пользование контейнеризации на базе Docker и Docker Compose позволило стандартизировать среду выполнения, упростить развертывание и обеспечить воспроизводимость системы в различных окружениях. Разработанные серви-сы, включая сервис управления миграциями и сервис авторизации, взаимодей-ствуют через четко определенные REST и gRPC API, что гарантирует их инте-грацию в сложные инфраструктуры и упрощает взаимодействие с внешними системами.
В процессе разработки были реализованы все запланированные функци-ональные и нефункциональные требования. Система поддерживает работу с реляционной базой данных PostgreSQL, обеспечивает аутентификацию и ав-торизацию на основе JWT, предоставляет механизмы логирования и монито-ринга операций. Особое внимание уделено автоматизации документирования: использование Swagger и Godoc позволило создать актуальную и доступную документацию API и кода, что упрощает сопровождение и дальнейшее разви-тие проекта.
Применение подхода API First, основанного на Protocol Buffers, обеспе-чило четкость и предсказуемость интерфейсов, автоматизацию генерации кода и документации. Реализация механизма передачи транзакций через контекст позволила централизовать управление транзакциями на уровне бизнес-логики, обеспечивая атомарность операций и повышая надежность системы. Структу-ра кодовой базы, спроектированая по принципам чистой архитектуры, гаран-тирует легкость тестирования, замены компонентов и расширения функцио-нальности.
Разработанное решение обладает потенциалом для дальнейшего разви-тия. Благодаря модульной архитектуре и использованию современных техно-логий, таких как Go, PostgreSQL и Docker, система может быть легко адапти-рована для поддержки дополнительных СУБД, интеграции с другими серви-сами или расширения функциональности, например, добавления аналитиче-ских инструментов или поддержки сложных сценариев миграций. Таким об-разом, разработанное приложение представляет собой надежное, гибкое и масштабируемое решение, соответствующее современным требованиям к управлению миграциями в реляционных базах данных.
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ
1. 	Date C. J. Введение в системы баз данных / 8-е. — Addison-Wesley, 2003.
2. 	Codd E. F. Реляционная модель данных для больших банков дан-ных // Коммуникации ACM. — 1970. — Т. 13, № 6. — С. 377–387.
3. 	Kim G., Behr K., Spafford G. Проект феникс: Роман об IT, DevOps и помощи бизнесу в победе. — IT Revolution Press, 2013.
4. 	Pataki B. Migrate: Миграции баз данных, написанные на go [Элек-тронный ресурс]. — 2018. — URL: https://github.com/golang-migrate/migrate (дата обращения: 26.02.2025).
5. 	Inc. P. Goose: Инструмент миграции баз данных для go [Элек-тронный ресурс]. — 2017. — URL: https://github.com/pressly/goose (дата обраще-ния: 28.02.2025).
6. 	Medjaoui M., Wilde E., Mitra R., Amundsen M. Непрерывное управ-ление API: Извлечение максимума из программы API. — O’Reilly Media, 2018.
7. 	Martin R. C. Чистая архитектура: Руководство мастера по струк-туре и дизайну программного обеспечения. — Prentice Hall, 2017.
8. 	Newman S. От монолита к микросервисам: Эволюционные паттер-ны трансформации монолита. — O’Reilly Media, 2019.
9. 	Google LLC. gRPC: Высокопроизводительный, открытый универ-сальный RPC-фреймворк [Электронный ресурс]. — 2021. — URL: https://grpc.io/docs/ (дата обращения: 19.03.2025).
10. 	Kleppmann M. Проектирование приложений, интенсивно работа-ющих с данными: Основные идеи надежных, масштабируемых и обслуживае-мых систем. — O’Reilly Media, 2017.
11. 	Ambler S. W., Sadalage P. J. Рефакторинг баз данных: Эволюцион-ный дизайн баз данных. — Addison-Wesley, 2012.
12. 	Zhang P. Практическое руководство по миграции больших баз данных. — CRC Press, 2017.
13. 	Инициатива OpenAPI. Спецификация OpenAPI [Электронный ре-сурс]. — 2024. — URL: https://spec.openapis.org/oas/latest.html (дата обращения: 15.03.2025).
14. 	Fielding R. T. Архитектурные стили и дизайн сетевых программ-ных архитектур: PhD thesis. — Калифорнийский университет, Ирвайн, 2000.
15. 	Глобальная группа разработки PostgreSQL. Документация PostgreSQL [Электронный ресурс]. — 2025. — URL: https://www.postgresql.org/docs/ (дата обращения: 17.03.2025).
16. 	Docker Inc. Документация Docker [Электронный ресурс]. — 2025. — URL: https://docs.docker.com/ (дата обращения: 17.03.2025).
17. 	Biazus G. Применение чистой архитектура в go [Электронный ре-сурс]. — 2021. — URL: https://blog.geisonbiazus.com/posts/applying-clean-architecture-in-go (дата обращения: 29.04.2025).
18. 	Fowler M. Паттерны архитектуры корпоративных приложений. — Addison-Wesley, 2010.
19. 	Burns B. Проектирование распределенных систем: Паттерны и па-радигмы для масштабируемых, надежных сервисов. — O’Reilly Media, 2016.
20. 	Авторы Go. Документация по языку программирования go [Электронный ресурс]. — 2024. — URL: https://go.dev/doc/ (дата обращения: 31.04.2025).
21. 	Nygard M. T. В релиз!: Проектирование и развертывание про-граммного обеспечения, готового к продуктовой среде. — Pragmatic Bookshelf, 2018.
ПРИЛОЖЕНИЕ А
 
Рисунок A.1 – Архитектура серверной компоненты приложения
ПРИЛОЖЕНИЕ Б
 
Рисунок B.1 – Диаграмма работы API для управления миграциями
